"""LLM ì„œë¹„ìŠ¤ í†µí•© ëª¨ë“ˆ - OpenAIì™€ Claudeë¥¼ ëª¨ë‘ ì§€ì›"""
from typing import List
from app.core.config import settings
from tenacity import retry, stop_after_attempt, wait_exponential
import time

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
def get_embeddings(texts: List[str]) -> List[List[float]]:
    """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
    
    Claudeë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° sentence-transformersë¥¼ ì‚¬ìš©í•˜ê³ ,
    OpenAIë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° OpenAI Embeddings APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    if settings.api_provider == "claude" or not settings.openai_api_key:
        # Claude ì‚¬ìš© ë˜ëŠ” OpenAI í‚¤ê°€ ì—†ëŠ” ê²½ìš° - sentence-transformers ì‚¬ìš©
        from sentence_transformers import SentenceTransformer
        
        model = SentenceTransformer(settings.embedding_model)
        embeddings = []
        batch_size = 10
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_embeddings = model.encode(batch, convert_to_numpy=True)
            embeddings.extend(batch_embeddings.tolist())
            time.sleep(0.1)
        
        return embeddings
    else:
        # OpenAI ì‚¬ìš©
        from openai import OpenAI
        
        client = OpenAI(api_key=settings.openai_api_key)
        embeddings = []
        batch_size = 10
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            response = client.embeddings.create(
                model=settings.openai_embedding_model,
                input=batch
            )
            for item in response.data:
                embeddings.append(item.embedding)
            time.sleep(1)
        
        return embeddings

def generate_answer(question: str, context: str) -> str:
    """ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±
    
    LLM ì—†ì´ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ëŒ€í™” ë‚´ìš©ì„ ì§ì ‘ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # LLM APIê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©
    if settings.api_provider == "claude" and settings.claude_api_key:
        # Claude ì‚¬ìš©
        from anthropic import Anthropic
        
        try:
            client = Anthropic(api_key=settings.claude_api_key)
            prompt = f"""ë‹¤ìŒ ìŠ¬ë™ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
            
ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
            response = client.messages.create(
                model=settings.claude_model,
                max_tokens=500,
                temperature=0.7,
                system="ë‹¹ì‹ ì€ íŒ€ì˜ ê³¼ê±° ìŠ¬ë™ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ ì  ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.",
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return response.content[0].text
        except Exception as e:
            # API ì—ëŸ¬ ì‹œ ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ í´ë°±
            pass
    
    elif settings.openai_api_key:
        # OpenAI ì‚¬ìš©
        from openai import OpenAI
        
        try:
            client = OpenAI(api_key=settings.openai_api_key)
            prompt = f"""ë‹¤ìŒ ìŠ¬ë™ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
            
ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
            response = client.chat.completions.create(
                model=settings.openai_chat_model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íŒ€ì˜ ê³¼ê±° ìŠ¬ë™ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ ì  ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            # API ì—ëŸ¬ ì‹œ ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ í´ë°±
            pass
    
    # LLM ì—†ì´ ì§ì ‘ ê´€ë ¨ ëŒ€í™” ë‚´ìš© ë°˜í™˜
    # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ê´€ë ¨ì„± ìˆëŠ” ë¶€ë¶„ ì¶”ì¶œ
    lines = context.split('\n')
    relevant_lines = []
    
    # ì§ˆë¬¸ í‚¤ì›Œë“œ ì¶”ì¶œ
    question_words = set(question.lower().split())
    
    # ê° ì¤„ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
    scored_lines = []
    for line in lines:
        if line.strip():
            # ì§ˆë¬¸ í‚¤ì›Œë“œì™€ ì¼ì¹˜í•˜ëŠ” ë‹¨ì–´ ìˆ˜ ê³„ì‚°
            line_words = set(line.lower().split())
            score = len(question_words & line_words)
            scored_lines.append((score, line))
    
    # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    scored_lines.sort(reverse=True)
    
    # ìƒìœ„ 5ê°œ ì¤„ ì„ íƒ
    for _, line in scored_lines[:5]:
        relevant_lines.append(line)
    
    if relevant_lines:
        answer = "ğŸ” ê´€ë ¨ ëŒ€í™” ë‚´ìš©:\n\n"
        answer += "\n".join(relevant_lines)
        answer += "\n\nğŸ’¡ ìœ„ ëŒ€í™” ë‚´ìš©ì´ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
        return answer
    else:
        return "ê´€ë ¨ëœ ëŒ€í™” ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
#!/usr/bin/env python3
"""ChromaDBì— ì €ìž¥ëœ ë°ì´í„° ì¡°íšŒ ìŠ¤í¬ë¦½íŠ¸"""

from app.core.database import get_collection
import json
from datetime import datetime

def check_db_data():
    """DBì— ì €ìž¥ëœ ëª¨ë“  ë°ì´í„° ì¡°íšŒ"""
    
    collection = get_collection()
    
    # 1. ì „ì²´ ê°œìˆ˜
    total_count = collection.count()
    print(f"=" * 60)
    print(f"ðŸ“Š ChromaDB ë°ì´í„° í˜„í™©")
    print(f"=" * 60)
    print(f"ì´ ì €ìž¥ëœ ì²­í¬ ìˆ˜: {total_count}ê°œ\n")
    
    if total_count == 0:
        print("âŒ ì €ìž¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 2. ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    results = collection.get()
    
    # 3. ë©”íƒ€ë°ì´í„° ë¶„ì„
    print(f"ðŸ“ ì €ìž¥ëœ ë°ì´í„° ìƒì„¸:")
    print(f"-" * 60)
    
    channels_set = set()
    users_set = set()
    sync_times = []
    
    for i, (doc_id, doc, metadata) in enumerate(zip(
        results['ids'], 
        results['documents'], 
        results['metadatas']
    ), 1):
        print(f"\n[ì²­í¬ {i}]")
        print(f"  ID: {doc_id[:8]}...")
        
        # í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²« 100ìž)
        preview = doc[:100].replace('\n', ' ')
        print(f"  í…ìŠ¤íŠ¸: {preview}...")
        
        # ë©”íƒ€ë°ì´í„°
        print(f"  ë©”íƒ€ë°ì´í„°:")
        print(f"    - ë©”ì‹œì§€ ìˆ˜: {metadata.get('message_count', 'N/A')}")
        # ìƒˆ í˜•ì‹ê³¼ êµ¬ í˜•ì‹ ëª¨ë‘ ì§€ì›
        if 'timestamp' in metadata:
            print(f"    - íƒ€ìž„ìŠ¤íƒ¬í”„: {metadata.get('timestamp', 'N/A')}")
            print(f"    - ì‚¬ìš©ìž: {metadata.get('user', 'N/A')}")
        else:
            print(f"    - ì‹œìž‘ ì‹œê°„: {metadata.get('first_ts', 'N/A')}")
            print(f"    - ì¢…ë£Œ ì‹œê°„: {metadata.get('last_ts', 'N/A')}")
            print(f"    - ì°¸ì—¬ ì‚¬ìš©ìž: {metadata.get('users', 'N/A')}")
        
        # Slack APIë¡œ ê°€ì ¸ì˜¨ ë°ì´í„°ì¸ ê²½ìš°
        if 'sync_time' in metadata:
            sync_time = metadata['sync_time']
            print(f"    - ë™ê¸°í™” ì‹œê°„: {sync_time}")
            sync_times.append(sync_time)
        
        # ì†ŒìŠ¤ ì •ë³´
        source = metadata.get('source', 'file_upload')
        print(f"    - ì†ŒìŠ¤: {source}")
        
        # í†µê³„ ìˆ˜ì§‘
        if 'users' in metadata:
            for user in metadata['users'].split(', '):
                if user:
                    users_set.add(user)
    
    # 4. ì „ì²´ í†µê³„
    print(f"\n{'=' * 60}")
    print(f"ðŸ“ˆ ì „ì²´ í†µê³„")
    print(f"{'=' * 60}")
    print(f"ì´ ì²­í¬ ìˆ˜: {total_count}ê°œ")
    print(f"ê³ ìœ  ì‚¬ìš©ìž ìˆ˜: {len(users_set)}ëª…")
    
    if users_set:
        print(f"ì‚¬ìš©ìž ëª©ë¡: {', '.join(sorted(users_set)[:10])}")
        if len(users_set) > 10:
            print(f"  ... ì™¸ {len(users_set) - 10}ëª…")
    
    if sync_times:
        latest_sync = max(sync_times)
        print(f"ìµœê·¼ ë™ê¸°í™”: {latest_sync}")
    
    # 5. ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print(f"\n{'=' * 60}")
    print(f"ðŸ” ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print(f"{'=' * 60}")
    
    # ìž„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰ (í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬)
    from app.services.llm_service import get_embeddings
    test_query = "í…ŒìŠ¤íŠ¸"
    query_embedding = get_embeddings([test_query])[0]
    
    search_results = collection.query(
        query_embeddings=[query_embedding],
        n_results=3
    )
    
    if search_results['documents'][0]:
        print(f"'{test_query}' ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 3ê°œ):")
        for i, (doc, distance) in enumerate(zip(
            search_results['documents'][0], 
            search_results['distances'][0]
        ), 1):
            preview = doc[:100].replace('\n', ' ')
            print(f"\n  {i}. ìœ ì‚¬ë„: {1 - distance:.2%}")
            print(f"     ë‚´ìš©: {preview}...")

def export_to_json():
    """DB ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    collection = get_collection()
    results = collection.get()
    
    data = []
    for doc_id, doc, metadata in zip(
        results['ids'], 
        results['documents'], 
        results['metadatas']
    ):
        data.append({
            'id': doc_id,
            'text': doc,
            'metadata': metadata
        })
    
    filename = f"db_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ë°ì´í„°ë¥¼ {filename}ì— ì €ìž¥í–ˆìŠµë‹ˆë‹¤.")
    return filename

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == '--export':
        export_to_json()
    else:
        check_db_data()